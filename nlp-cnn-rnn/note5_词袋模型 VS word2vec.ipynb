{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 词袋模型\n",
    "   前面几篇笔记几乎都采用的词袋模型，该模型使用one-hot将词转换成向量的形式，故有N个词就会构成N个维度。one-hot向量比较简单也容易理解，但是有很多问题。比如当加入新词时，整个向量的长度会改变，并且存在维度过高难以计算的问题，以及向量的表示方法很难体现两个词之间的关系。\n",
    "> 词袋模型的特点：离散、高维、稀疏\n",
    ">> 优点：简单易懂、稀疏存储 \n",
    ">> 缺点：维度灾难、词汇鸿沟\n",
    "#### word2vec\n",
    "    word2vec得到的词的向量形式（简称“词向量”，更学术化的翻译是“词嵌入”）则可以自由控制维度，一般是100左右。\n",
    "    \n",
    "    word2vec作为神经概率语言模型的输入，其本身其实是神经概率模型的副产品，是为了通过神经网络学习某个语言模型而产生的中间结果。具体来说，“某个语言模型”指的是“CBOW”和“Skip-gram”。具体学习过程会用到两个降低复杂度的近似方法——Hierarchical Softmax或Negative Sampling。两个模型乘以两种方法，一共有四种实现。\n",
    "    \n",
    "   >“CBOW”和“Skip-gram”都是浅层神经网络(不含隐藏层)。\n",
    "   >> CBOW是通过当前词的上下文关联词预测当前词的概率；\n",
    "   >> Skip-gram是通过当前词预测上下文关联词的概率\n",
    "   \n",
    "   >> Hierarchical Softmax的负例是二叉树的其他路径；\n",
    "   >> Negative Sampling的负例是随机挑选出来的，随机挑选能提高运行速度，改善模型质量\n",
    "    \n",
    "> word2vec的特点：连续、低维、稠密\n",
    "\n",
    "[参考文档](http://www.hankcs.com/nlp/word2vec.html)\n",
    "\n",
    "https://spaces.ac.cn/archives/4304\n",
    "\n",
    "https://blog.csdn.net/u013421629/article/details/82462606"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gensim.word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import pandas as pd\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sens = LineSentence('./cnews/cnews.val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>体育</td>\n",
       "      <td>黄蜂vs湖人首发：科比带伤战保罗 加索尔救赎之战 新浪体育讯北京时间4月27日，NBA季后赛...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            content\n",
       "0    体育  黄蜂vs湖人首发：科比带伤战保罗 加索尔救赎之战 新浪体育讯北京时间4月27日，NBA季后赛..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./cnews/cnews.val.txt', sep='\\t', encoding='utf-8', header=None, names=['label','content'])\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#停用词\n",
    "stop_words = pd.read_csv('./cnews/stopwords.txt', index_col = False, quoting=3, sep='\\t',\n",
    "                        names = ['stopword'], encoding='utf-8')\n",
    "\n",
    "content = data.content.values.tolist()\n",
    "stopword = stop_words.stopword.values.tolist()\n",
    "\n",
    "texts = []\n",
    "\n",
    "for i in content[:500]: \n",
    "    #均为体育新闻\n",
    "    seg = list(j for j in jieba.lcut(i) if str(j) not in stopword and len(j)>1)\n",
    "    texts.append(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['黄蜂', '湖人', '首发', '科比', '带伤', '保罗', '加索尔', '救赎', '之战', '新浪', '体育讯', '北京', '时间', 'NBA', '季后赛', '首轮', '洛杉矶', '湖人', '主场', '迎战', '新奥尔良', '黄蜂', '此前', '比赛', '战成', '本场', '比赛', '两支', '球队', '赛前', '公布', '首发', '阵容', '湖人队', '费舍尔', '科比', '阿泰斯特', '加索尔', '拜纳姆', '黄蜂队', '保罗', '贝里', '内利', '阿里', '兰德', '奥卡福', '新浪', 'NBA', '官方', '微博', '新浪', 'NBA', '湖人', '新闻动态', '微博', '新浪', 'NBA', '专题', '黄蜂', '湖人', '图文', '直播室', '新浪', '体育'], ['1.7', '击救', '马刺', '王朝', '危难', '新秀', '新浪', '体育讯', '刚刚', '结束', '比赛', '回到', '主场', '马刺', '加时', '110', '103', '惊险', '战胜', '主场', '观众', '见证', '黑八', '尴尬', '常规', '时间', '关头', '加里', '尼尔', '命中', '一记', '三分', '进球', '马刺', '比赛', '带进', '加时', '最终', '翻盘', '成功', '波波维奇', '教练', '安排', '详细', '告诉', '机会', '出手', '邓肯', '掩护', '挡住', '防守', '球员', '投篮', '视野', '出手', '命中', '这记', '价值连城', '尼尔', '依然', '低调', '问及', '职业生涯', '投篮', '没错', '目前为止', '赛季', '听说', '尼尔', '西部', '第一', '马刺', '缺少', '拼图', '季后赛', '赢球', '回家', '钓鱼', '关键', '比赛', '命中', '球队', '续命', '关键球', '成功', '背后', '隐藏', '一段', '鲜为人知', '艰难', '历程', '效力', '拉塞尔', '大学', '拿下', '赛区', '最佳', '新人', '一宗', '强奸', '指控', '球队', '开除', '好转', '名不见经传', '图森', '大学', '打出', '很漂亮', '数据', '表现', '无奈', '身高', '学校', '选秀', '落选', '落选', 'NBA', '球队', '签下', '合同', '邀请', '参加', '训练营', '选择', '联盟', '混迹', '薪水', '微薄', '高中', '教师', '一段时间', '土耳其', '名不见经传', '俱乐部', '邀请', '打球', '怀着', '终于', '有球', '激动', '心情', '踏上', '欧洲', '之旅', '球队', '打出', '名气', '一举', '土耳其', '联赛', '耀眼', '明星', '一年', '西班牙', '豪门', '巴塞罗那', '看中', 'NBA', '混迹', '瓦罗', '阿根廷', '国家队', '主控', '桑切斯', '并肩作战', '这名', '异国', '流浪汉', '辗转', '意大利', '贝纳通', '西班牙', '马拉加', '两只', '欧洲', '颇具', '实力', '队伍', '经历', '三年', '大洋彼岸', '磨练', '马刺', '一纸', '三年', '合约', '终于', '最初', '梦想', '马刺', '尼尔', '时常', '想起', '旅欧', '归来', '鲍文', '欧洲', '顶尖', '得分', '好手', '波波维奇', '麾下', '兢兢业业', '防守', '投中', '空位', '三分', '一名', '完美', '角色', '球员', '眼中', '尼尔', '射手', '能力', '远不止', '比赛', '绝杀', '证明', '一颗', '超人', '心脏', 'francischen']]\n"
     ]
    }
   ],
   "source": [
    "print(texts[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens = texts.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型\n",
    "model = Word2Vec(sens, size=128, window=3, min_count=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save('./word_emdedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型\n",
    "model = Word2Vec.load('./word_emdedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "黎双富 0.9984898567199707\n",
      "迈阿密 0.9984685778617859\n",
      "官方 0.9976723194122314\n",
      "雅虎 0.9970170259475708\n",
      "NBA 0.9964408874511719\n",
      "微博 0.9938219785690308\n",
      "发自 0.9937679171562195\n",
      "00 0.9932857751846313\n",
      "新闻动态 0.9931809306144714\n",
      "官网 0.9911702871322632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#测试词语之间的相似度\n",
    "items = model.most_similar('体育')\n",
    "for i,j in items:\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "黎双富 0.9984898567199707\n",
      "迈阿密 0.9984685778617859\n",
      "官方 0.9976723194122314\n",
      "雅虎 0.9970170259475708\n",
      "NBA 0.9964408874511719\n",
      "微博 0.9938219785690308\n",
      "发自 0.9937679171562195\n",
      "00 0.9932857751846313\n",
      "新闻动态 0.9931809306144714\n",
      "官网 0.9911702871322632\n"
     ]
    }
   ],
   "source": [
    "#测试词语之间的相似度\n",
    "items = model.wv.most_similar('体育')\n",
    "for i,j in items:\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9967143040273748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tt=model.similarity('得分',  '投中')\n",
    "\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985934569655914\n"
     ]
    }
   ],
   "source": [
    "tt=model.wv.similarity('能力',  '成功')\n",
    "\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6195670108377953\n"
     ]
    }
   ],
   "source": [
    "tt=model.wv.similarity('新浪',  '成功')\n",
    "\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985490506450232\n"
     ]
    }
   ],
   "source": [
    "tt=model.wv.similarity('成功',  '失败')\n",
    "\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990024484055975\n"
     ]
    }
   ],
   "source": [
    "tt=model.wv.similarity('成功',  '尴尬')\n",
    "\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9810751637767183\n"
     ]
    }
   ],
   "source": [
    "tt=model.wv.similarity('失败',  '尴尬')\n",
    "\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上文本全部是体育新闻，相似度过高，所以训练效果不够好，可以增加训练集或者加入其他类型的文本进行训练"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
