{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 以train数据集作为全部数据集使用以下模型进行建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集预处理\n",
    "    -读取，分词，去除停用词\n",
    "    -切分数据集\n",
    "    -向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>体育</td>\n",
       "      <td>马晓旭意外受伤让国奥警惕 无奈大雨格外青睐殷家军记者傅亚雨沈阳报道 来到沈阳，国奥队依然没有...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            content\n",
       "0    体育  马晓旭意外受伤让国奥警惕 无奈大雨格外青睐殷家军记者傅亚雨沈阳报道 来到沈阳，国奥队依然没有..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./cnews/cnews.train.txt', sep='\\t', encoding='utf-8', header=None, names=['label','content'])\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stopword\n",
       "0        !\n",
       "1        \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#停用词\n",
    "stop_words = pd.read_csv('./cnews/stopwords.txt', index_col = False, quoting=3, sep='\\t',\n",
    "                        names = ['stopword'], encoding='utf-8')\n",
    "stop_words.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = data.content.values.tolist()\n",
    "label = data.label.values.tolist()\n",
    "stopword = stop_words.stopword.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去除停用词\n",
    "def preprocess_text(content,label,result):\n",
    "    for i in range(len(content)):\n",
    "        try:\n",
    "            segs = jieba.lcut(content[i])\n",
    "            segs = filter(lambda x: len(x)>1, segs)\n",
    "            segs = filter(lambda x: x not in stopword, segs)\n",
    "            result.append((\" \".join(segs), label[i]))\n",
    "        except:\n",
    "            print(content[i])\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/sr/qrwj9nk92555240wtx2w98wh0000gn/T/jieba.cache\n",
      "Loading model cost 0.652 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('马晓旭 意外 受伤 国奥 警惕 无奈 大雨 青睐 殷家 傅亚雨 沈阳 报道 来到 沈阳 国奥队 依然 摆脱 雨水 困扰 国奥队 日常 训练 再度 大雨 干扰 无奈 之下 队员 慢跑 分钟 草草收场 国奥队 奥体中心 外场 训练 阴沉沉 气象预报 显示 当天 沈阳 大雨 幸好 队伍 训练 干扰 球队 抵达 训练场 大雨 几个 小时 丝毫 停下来 试一试 态度 球队 当天 例行 训练 分钟 天气 转好 迹象 保护 球员 国奥队 中止 当天 训练 全队 返回 酒店 训练 足球队 稀罕 奥运会 全队 变得 娇贵 沈阳 一周 训练 国奥队 保证 现有 球员 出现意外 伤病 情况 影响 正式 比赛 这一 阶段 控制 训练 受伤 控制 感冒 疾病 队伍 放在 位置 抵达 沈阳 后卫 冯萧霆 训练 冯萧霆 长春 患上 感冒 参加 塞尔维亚 热身赛 队伍 介绍 冯萧霆 发烧 症状 两天 静养 休息 感冒 恢复 训练 冯萧霆 例子 国奥队 对雨中 训练 显得 特别 谨慎 担心 球员 受凉 引发 感冒 非战斗 减员 女足 队员 马晓旭 热身赛 受伤 导致 无缘 奥运 前科 沈阳 国奥队 警惕 训练 嘱咐 队员 动作 再出 事情 一位 工作人员 长春 沈阳 雨水 一路 伴随 国奥队 长春 几次 训练 大雨 搅和 没想到 沈阳 碰到 事情 一位 国奥 球员 雨水 青睐 不解',\n",
       "  '体育')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "preprocess_text(content,label,result)\n",
    "result[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37500,) (12500,)\n"
     ]
    }
   ],
   "source": [
    "# 打乱顺序，生成训练集\n",
    "random.shuffle(result)\n",
    "\n",
    "x,y = zip(*result)\n",
    "#把原始数据集切分为训练集和测试集\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1)\n",
    "\n",
    "print(np.shape(x_train),np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=2000, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='word', \n",
    "                        ngram_range=(1,3), #ngram=1,2,3\n",
    "                        max_features=2000)\n",
    "vec.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classfier = MultinomialNB()\n",
    "classfier.fit(vec.transform(x_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92312"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#准确率\n",
    "classfier.score(vec.transform(x_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM\n",
    "\n",
    "[参数说明](https://m.imooc.com/article/details?article_id=40903)\n",
    "\n",
    "https://blog.csdn.net/qq_37879432/article/details/78598995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "#svm（linear、rbf、sigmoid为核的SVM）\n",
    "clf_linear = svm.SVC(kernel='linear')\n",
    "# clf_rbf = svm.SVC(kernel='rbf')\n",
    "# clf_sigmoid = svm.SVC(kernel='sigmoid')\n",
    "clf_linear.fit(vec.transform(x_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94096"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linear.score(vec.transform(x_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 主题模型 LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "random.shuffle(content)\n",
    "for i in content[:100]:\n",
    "    seg = list(j for j in jieba.lcut(i) if str(j) not in stopword and len(j)>1)\n",
    "    texts.append(seg)\n",
    "    \n",
    "dic = Dictionary(texts)\n",
    "doc = [dic.doc2bow(i) for i in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(doc,num_topics=5,id2word=dic,passes=1) \n",
    "#pass 遍历次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.005*\"中国\" + 0.005*\"电影\" + 0.004*\"项目\" + 0.003*\"经济\" + 0.003*\"汇率\"'),\n",
       " (1, '0.008*\"电影\" + 0.005*\"公司\" + 0.004*\"中国\" + 0.004*\"市场\" + 0.003*\"投资\"'),\n",
       " (2, '0.004*\"项目\" + 0.003*\"中国\" + 0.003*\"电影\" + 0.003*\"亿元\" + 0.002*\"球员\"'),\n",
       " (3, '0.006*\"中国\" + 0.005*\"项目\" + 0.003*\"基金\" + 0.003*\"投资\" + 0.003*\"市场\"'),\n",
       " (4, '0.006*\"基金\" + 0.004*\"投资\" + 0.003*\"债券\" + 0.003*\"亿元\" + 0.003*\"电影\"')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(num_topics=5,num_words=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
