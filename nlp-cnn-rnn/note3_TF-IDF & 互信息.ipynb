{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF(Term Frequency -  Inverse Document Frequency，即“词频-逆文本频率”)\n",
    "\n",
    "    TF：即“词频”，即文本中各个词的出现频率统计。\n",
    "    IDF：即“逆文本频率”。帮助我们来反映这个词的重要性，进而修正仅仅用词频表示的词特征值。\n",
    "       概括来讲， IDF反应了一个词在所有文本中出现的频率，如果一个词在很多的文本中出现，那么它的IDF值应该低。而反过来如果一个词在比较少的文本中出现，那么它的IDF值应该高。比如一些专业的名词如“Machine Learning”。这样的词IDF值应该高。一个极端的情况，如果一个词在所有的文本中都出现，那么它的IDF值应该为0。\n",
    "       \n",
    "    一个词x的IDF的基本公式如下：\n",
    "    > IDF(x)= log(N/N(x))  \n",
    "    >> N: 代表语料库中文本的总数;N(x):代表语料库中包含词x的文本总数。\n",
    "    以上公司当分母为0时无法计算(如某一个生僻词在语料库中没有)，故对以上公式进行平滑处理，为:\n",
    "    >IDF(x)= log((N+1)/(N(x)+1))\n",
    "    \n",
    "    接下来计算某个词的TF-IDF值：\n",
    "    TF-IDF(x) = TF(x)*IDF(x) \n",
    "    > TF(x):值词x在当前文本中的词频\n",
    "    \n",
    "   [参考文章](https://www.cnblogs.com/pinard/p/6693230.html)\n",
    "   \n",
    "### 下面随机抽取小样本数据将文本矩阵化，并使用词袋模型，计算TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics as mr\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>体育</td>\n",
       "      <td>黄蜂vs湖人首发：科比带伤战保罗 加索尔救赎之战 新浪体育讯北京时间4月27日，NBA季后赛...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>体育</td>\n",
       "      <td>1.7秒神之一击救马刺王朝于危难 这个新秀有点牛！新浪体育讯在刚刚结束的比赛中，回到主场的马...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>体育</td>\n",
       "      <td>1人灭掘金！神般杜兰特！ 他想要分的时候没人能挡新浪体育讯在NBA的世界里，真的猛男，敢于直...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>体育</td>\n",
       "      <td>韩国国奥20人名单：朴周永领衔 两世界杯国脚入选新浪体育讯据韩联社首尔9月17日电 韩国国奥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>体育</td>\n",
       "      <td>天才中锋崇拜王治郅 周琦：球员最终是靠实力说话2月14日从土耳其男篮邀请赛回到北京之后，周琦...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            content\n",
       "0    体育  黄蜂vs湖人首发：科比带伤战保罗 加索尔救赎之战 新浪体育讯北京时间4月27日，NBA季后赛...\n",
       "1    体育  1.7秒神之一击救马刺王朝于危难 这个新秀有点牛！新浪体育讯在刚刚结束的比赛中，回到主场的马...\n",
       "2    体育  1人灭掘金！神般杜兰特！ 他想要分的时候没人能挡新浪体育讯在NBA的世界里，真的猛男，敢于直...\n",
       "3    体育  韩国国奥20人名单：朴周永领衔 两世界杯国脚入选新浪体育讯据韩联社首尔9月17日电 韩国国奥...\n",
       "4    体育  天才中锋崇拜王治郅 周琦：球员最终是靠实力说话2月14日从土耳其男篮邀请赛回到北京之后，周琦..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_table('./cnews/cnews.val.txt',sep='\\t',encoding='utf-8',header=None,names=['label','content'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2) (5, 2)\n"
     ]
    }
   ],
   "source": [
    "df1 = train[train.label=='体育'].sample(frac=0.01,random_state=1)\n",
    "df2 = train[train.label=='娱乐'].sample(frac=0.01,random_state=1)\n",
    "print(df1.shape,df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1,df2])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>体育</td>\n",
       "      <td>23+7+6！韦德一条龙暴扣 三巨头就只有他还在战斗新浪体育讯23分、7助攻、6篮板、1抢断...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                            content\n",
       "304    体育  23+7+6！韦德一条龙暴扣 三巨头就只有他还在战斗新浪体育讯23分、7助攻、6篮板、1抢断..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stopword\n",
       "0        !\n",
       "1        \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = pd.read_csv('./cnews/stopwords.txt',index_col=False, quoting=3,sep='\\t',\n",
    "                        names=['stopword'],encoding='utf-8')\n",
    "stop_words.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词，去除停用词\n",
    "content = df.content.values.tolist()\n",
    "label = df.label.values.tolist()\n",
    "stopwords = stop_words.stopword.values.tolist()\n",
    "\n",
    "def preprocess_text(content,label,result):\n",
    "    for i in range(len(content)):\n",
    "        try:\n",
    "            segs = jieba.lcut(content[i])\n",
    "            segs = filter(lambda x:len(x)>1,segs)\n",
    "            segs = filter(lambda x: x not in stopwords,segs)\n",
    "            result.append((\" \".join(segs),label[i]))\n",
    "        except:\n",
    "            print(content[i])\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/0d/j7b0cl_s2qx7rt2p7_vp4sfr0000gp/T/jieba.cache\n",
      "Loading model cost 0.792 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "preprocess_text(content,label,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('韦德 一条龙 暴扣 巨头 新浪 体育讯 助攻 篮板 抢断 盖帽 热火 最终 客场 无力回天 打出 数据 德维恩 韦德 问心无愧 热火 主力阵容 唯一 发挥 一刻 勇士 只不过 主场 作战 凯尔特人 信心 飙升 双拳 难敌 四手 韦德 只得 吞下 失利 苦果 两场 搞定 老辣 绿衫 韦德 进攻 予取予求 走上 罚球线 侵略性 可见一斑 凯尔特人 碰到 暴走 韦德 确实 办法 这场 比赛 回到 主场 凯尔特人 开场 攻击性 十足 保罗 皮尔斯 凯文 加内特 开场 哨响 卯足了劲 热火 韦德 是从 松懈 客场 志在 总冠军 韦德 阻碍 韦德 超级 巨星 得分 之外 进攻 端的 作用 关键 第二节 剩下 分多钟 乔尔 安东尼 马里奥 查尔 默斯 传球 得分 进攻 归功于 韦德 热火 进攻 配合 韦德 篮筐 右侧 接球 原本 另一侧 凯文 加内特 协防 韦德 并未 纠缠 第一 时间 将球 传到 外线 查尔 默斯 查尔 默斯 停顿 塞进 内线 安东尼 防守 安东尼 加内特 顾忌 查尔 默斯 传球 韦德 并未 回防 到位 安东尼 面对 补防 梅因 奥尼尔 篮下 轻松 得分 热火 阵容 查尔 默斯 安东尼 两名 替补 合力 表现 抢眼 两位 替补 发挥 之外 第二节 韦德 创造 机会 韦德 进攻 端起 推进 作用 助攻 可惜 詹姆斯 这方面 不好 克里斯 波什 睡醒 模样 一己 之力 单挑 凯尔特人 皮尔斯 加内特 韦德 竭尽所能 凯尔特人 追回 一场 热火 并不需要 紧张 绿衫 经验丰富 球队 棒子 打死 热火 关键 一点 韦德 发挥 替补 发挥 下一场 胜利 奠定 基础 XWT185',\n",
       "  '体育')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = zip(*result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 191)\t0.6610270076661171\n",
      "  (0, 71)\t0.04131418797913232\n",
      "  (0, 101)\t0.02369036158888635\n",
      "  (0, 12)\t0.03213552402585269\n",
      "  (0, 27)\t0.08262837595826464\n",
      "  (0, 159)\t0.04131418797913232\n",
      "  (0, 128)\t0.2891993158539262\n",
      "  (0, 112)\t0.036145032506955825\n",
      "  (0, 64)\t0.0971994068500506\n",
      "  (0, 104)\t0.04131418797913232\n",
      "  (0, 82)\t0.04131418797913232\n",
      "  (0, 35)\t0.1445801300278233\n",
      "  (0, 6)\t0.08262837595826464\n",
      "  (0, 18)\t0.18072516253477913\n",
      "  (0, 52)\t0.04131418797913232\n",
      "  (0, 99)\t0.04131418797913232\n",
      "  (0, 166)\t0.07229006501391165\n",
      "  (0, 185)\t0.2429985171251265\n",
      "  (0, 183)\t0.04131418797913232\n",
      "  (0, 169)\t0.04131418797913232\n",
      "  (0, 25)\t0.04131418797913232\n",
      "  (0, 120)\t0.03213552402585269\n",
      "  (0, 47)\t0.04131418797913232\n",
      "  (0, 76)\t0.0971994068500506\n",
      "  (0, 14)\t0.04131418797913232\n",
      "  :\t:\n",
      "  (9, 98)\t0.05488399330623517\n",
      "  (9, 37)\t0.05488399330623517\n",
      "  (9, 51)\t0.10976798661247034\n",
      "  (9, 55)\t0.07667707481026079\n",
      "  (9, 79)\t0.21953597322494067\n",
      "  (9, 147)\t0.10976798661247034\n",
      "  (9, 116)\t0.05488399330623517\n",
      "  (9, 58)\t0.05488399330623517\n",
      "  (9, 181)\t0.09603401732922451\n",
      "  (9, 8)\t0.10976798661247034\n",
      "  (9, 48)\t0.05488399330623517\n",
      "  (9, 88)\t0.12912492913143406\n",
      "  (9, 15)\t0.4519372519600192\n",
      "  (9, 17)\t0.1936873936971511\n",
      "  (9, 38)\t0.12912492913143406\n",
      "  (9, 105)\t0.1936873936971511\n",
      "  (9, 65)\t0.12912492913143406\n",
      "  (9, 54)\t0.12912492913143406\n",
      "  (9, 115)\t0.1936873936971511\n",
      "  (9, 195)\t0.12912492913143406\n",
      "  (9, 42)\t0.3873747873943022\n",
      "  (9, 117)\t0.2582498582628681\n",
      "  (9, 142)\t0.1936873936971511\n",
      "  (9, 83)\t0.12912492913143406\n",
      "  (9, 49)\t0.12912492913143406\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(max_features=200) #为了便于观察，仅输出前200个词\n",
    "trans = TfidfTransformer()\n",
    "tfidf = trans.fit_transform(vec.fit_transform(x))\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tm', '一人', '一位', '一场', '一年', '一点', '主场', '主帅', '主角奖', '人民币', '伊朗', '传球', '体育讯', '作品', '保罗', '儿子', '克劳德', '入殓', '凯尔特人', '凯撒', '凯文', '制片', '制片人', '前往', '剧情', '办法', '加内特', '助攻', '北京', '医生', '千万元', '华纳', '单防', '原本', '去世', '发挥', '发现', '发行', '发高烧', '受伤', '变得', '只会', '台湾', '合作', '合同', '名单', '哈尼', '回到', '国际', '外语片', '多年', '大奖', '失利', '夺冠', '奖座秀', '奥斯卡', '好消息', '好莱坞', '威廉', '娱乐', '季后赛', '孩子', '安东尼', '实力', '客场', '家中', '对手', '对抗', '导演', '将会', '山猫', '巨头', '巴黎', '希望', '帕金斯', '并未', '开场', '弗斯', '影坛', '影帝', '影片', '得分', '德维恩', '心诚则灵', '总冠军', '总裁', '情况', '感情', '感言', '打死', '打球', '执导', '扮演', '投入', '报道', '拍摄', '拿下', '接受', '接过', '搞定', '故事', '新浪', '新闻', '新闻节目', '无力回天', '日本', '时间', '晚间', '普里', '更好', '替补', '最佳', '最终', '期间', '未来', '本木雅弘', '机场', '李岗', '查尔', '横扫', '比赛', '法国', '法国电影', '法拉', '波士顿', '淘汰', '湖人', '演员', '热火', '爆出', '父亲', '父母', '片中', '球员', '球迷', '球队', '电影', '电影节', '男人', '留在', '百万富翁', '皮尔斯', '真诚', '眼神', '知名', '短暂', '短片', '票房', '禁止', '福尔摩斯', '科林斯', '童星', '第一', '第一场', '第一部', '第二节', '第六场', '第四节', '策略', '篮板', '系列赛', '紧张', '经历', '继续下去', '续约', '绿军', '绿衫', '网站', '罗伯特', '罚球线', '老三', '老鹰', '肯定', '胜利', '膝盖', '自由', '荣誉', '落后', '蓝色', '表现', '解决', '该片', '贝里', '走上', '身体', '进攻', '迪卡', '里奇', '闪电侠', '阵容', '面对', '韦德', '顽强', '预计', '首轮', '香港', '魔兽', '魔术', '黄蜂', '默斯']\n"
     ]
    }
   ],
   "source": [
    "'''get_feature_names()可看到所有文本的关键字'''\n",
    "print(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'韦德': 191, '巨头': 71, '新浪': 101, '体育讯': 12, '助攻': 27, '篮板': 159, '热火': 128, '最终': 112, '客场': 64, '无力回天': 104, '德维恩': 82, '发挥': 35, '主场': 6, '凯尔特人': 18, '失利': 52, '搞定': 99, '绿衫': 166, '进攻': 185, '走上': 183, '罚球线': 169, '办法': 25, '比赛': 120, '回到': 47, '开场': 76, '保罗': 14, '皮尔斯': 141, '凯文': 20, '加内特': 26, '总冠军': 84, '得分': 81, '第二节': 155, '安东尼': 62, '查尔': 118, '默斯': 199, '传球': 11, '原本': 33, '并未': 75, '第一': 152, '时间': 106, '面对': 190, '阵容': 189, '替补': 110, '表现': 179, '一场': 3, '紧张': 161, '球队': 135, '打死': 89, '一点': 5, '胜利': 173, '受伤': 39, '闪电侠': 188, 'tm': 0, '顽强': 192, '北京': 28, '波士顿': 124, '球迷': 134, '打球': 90, '一位': 2, '对抗': 67, '身体': 184, '球员': 133, '新闻': 102, '膝盖': 174, '肯定': 172, '医生': 29, '情况': 86, '魔兽': 196, '科林斯': 150, '单防': 32, '魔术': 197, '季后赛': 60, '首轮': 194, '山猫': 70, '帕金斯': 74, '对手': 66, '横扫': 119, '老鹰': 171, '策略': 158, '系列赛': 160, '一人': 1, '第四节': 157, '落后': 177, '留在': 139, '黄蜂': 198, '第六场': 156, '湖人': 126, '实力': 63, '第一场': 153, '爆出': 129, '拿下': 96, '蓝色': 178, '眼神': 143, '未来': 114, '将会': 69, '续约': 164, '主帅': 7, '弗斯': 77, '夺冠': 53, '报道': 94, '淘汰': 125, '好消息': 56, '绿军': 165, '感情': 87, '接受': 97, '合同': 44, '一年': 4, '多年': 50, '总裁': 85, '解决': 180, '希望': 73, '投入': 93, '自由': 175, '老三': 170, '只会': 41, '变得': 40, '更好': 109, '继续下去': 163, '短暂': 145, '法国电影': 122, '克劳德': 16, '贝里': 182, '去世': 34, '娱乐': 59, '法国': 121, '知名': 144, '电影': 136, '巴黎': 72, '新闻节目': 103, '制片人': 22, '晚间': 107, '影坛': 78, '制片': 21, '拍摄': 95, '影片': 80, '期间': 113, '作品': 13, '导演': 68, '电影节': 137, '最佳': 111, '荣誉': 176, '接过': 98, '合作': 43, '经历': 162, '发行': 37, '男人': 138, '演员': 127, '大奖': 51, '凯撒': 19, '父母': 131, '父亲': 130, '执导': 91, '第一部': 154, '剧情': 24, '短片': 146, '奥斯卡': 55, '孩子': 61, '故事': 100, '发现': 36, '影帝': 79, '百万富翁': 140, '票房': 147, '童星': 151, '千万元': 30, '人民币': 9, '伊朗': 10, '好莱坞': 57, '禁止': 148, '迪卡': 186, '普里': 108, '法拉': 123, '哈尼': 46, '机场': 116, '名单': 45, '前往': 23, '威廉': 58, '该片': 181, '预计': 193, '华纳': 31, '片中': 132, '扮演': 92, '网站': 167, '福尔摩斯': 149, '罗伯特': 168, '主角奖': 8, '里奇': 187, '国际': 48, '感言': 88, '儿子': 15, '入殓': 17, '发高烧': 38, '日本': 105, '家中': 65, '奖座秀': 54, '本木雅弘': 115, '香港': 195, '台湾': 42, '李岗': 117, '真诚': 142, '心诚则灵': 83, '外语片': 49}\n"
     ]
    }
   ],
   "source": [
    "'''vocabulary_可看到所有文本的关键字和其位置'''\n",
    "print(vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 5]\n",
      " [2 0 2 ... 0 0 0]\n",
      " [0 2 0 ... 6 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "'''toarray()可看到词频矩阵的结果'''\n",
    "print(vec.fit_transform(x).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.24299852]\n",
      " [0.18949997 0.         0.14093671 ... 0.         0.         0.        ]\n",
      " [0.         0.10362647 0.         ... 0.31087942 0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.06909125 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041314</td>\n",
       "      <td>0.082628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.661027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140937</td>\n",
       "      <td>0.070468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563823</td>\n",
       "      <td>0.161092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.103626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.829012</td>\n",
       "      <td>0.310879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756935</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6    \\\n",
       "0  0.0000  0.000000  0.000000  0.036145  0.000000  0.041314  0.082628   \n",
       "1  0.1895  0.000000  0.140937  0.070468  0.000000  0.000000  0.000000   \n",
       "2  0.0000  0.103626  0.000000  0.000000  0.000000  0.088092  0.000000   \n",
       "3  0.0000  0.000000  0.000000  0.043304  0.000000  0.000000  0.197989   \n",
       "4  0.0000  0.000000  0.000000  0.000000  0.159337  0.000000  0.000000   \n",
       "5  0.0000  0.000000  0.028974  0.000000  0.000000  0.000000  0.000000   \n",
       "6  0.0000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7  0.0000  0.000000  0.069091  0.000000  0.000000  0.000000  0.000000   \n",
       "8  0.0000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9  0.0000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        7         8         9      ...          190       191       192  \\\n",
       "0  0.000000  0.000000  0.000000    ...     0.036145  0.661027  0.000000   \n",
       "1  0.000000  0.000000  0.000000    ...     0.000000  0.563823  0.161092   \n",
       "2  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.049497   \n",
       "4  0.159337  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.000000  0.000000    ...     0.028974  0.000000  0.000000   \n",
       "6  0.000000  0.000000  0.496027    ...     0.000000  0.000000  0.000000   \n",
       "7  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "8  0.000000  0.111719  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "9  0.000000  0.109768  0.000000    ...     0.048017  0.000000  0.000000   \n",
       "\n",
       "        193       194       195       196       197       198       199  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.242999  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.044046  0.000000  0.829012  0.310879  0.000000  0.000000  \n",
       "3  0.000000  0.049497  0.000000  0.000000  0.000000  0.756935  0.000000  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7  0.078972  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8  0.111719  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "9  0.000000  0.000000  0.129125  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[10 rows x 200 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#便于观察 转化成df目测一下特征分布 共计200个词向量特征\n",
    "tfidf_df = pd.DataFrame(tfidf.toarray())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#该方法似乎更适用于提取每个文本的关键词 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用互信息进行特征筛选\n",
    "\n",
    "点互信息(PMI): 衡量两个事物之间的相关性\n",
    "> 举个自然语言处理中的例子来说，我们想衡量like这个词的极性（正向情感还是负向情感）。我们可以预先挑选一些正向情感的词，比如good。然后我们算like跟good的PMI。\n",
    "    \n",
    "互信息(MI): 其衡量的是两个随机变量之间的相关性，即一个随机变量中包含的关于另一个随机变量的信息量。\n",
    "> 互信息其实就是对X和Y的所有可能的取值情况的点互信息PMI的加权和。\n",
    "\n",
    "[参考文章](https://blog.csdn.net/u013710265/article/details/72848755)\n",
    "\n",
    "[mutual_info_classif文档](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html)\n",
    "\n",
    "[mutual_info_score文档](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mutual_info_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   190  191  192  193  \\\n",
       "0    0    0    0    1    0    1    2    0    0    0 ...     1   16    0    0   \n",
       "1    2    0    2    1    0    0    0    0    0    0 ...     0    7    2    0   \n",
       "2    0    2    0    0    0    2    0    0    0    0 ...     0    0    0    0   \n",
       "3    0    0    0    1    0    0    4    0    0    0 ...     0    0    1    0   \n",
       "4    0    0    0    0    3    0    0    3    0    0 ...     0    0    0    0   \n",
       "5    0    0    1    0    0    0    0    0    0    0 ...     1    0    0    0   \n",
       "6    0    0    0    0    0    0    0    0    0    3 ...     0    0    0    0   \n",
       "7    0    0    1    0    0    0    0    0    0    0 ...     0    0    0    1   \n",
       "8    0    0    0    0    0    0    0    0    1    0 ...     0    0    0    1   \n",
       "9    0    0    0    0    0    0    0    0    2    0 ...     1    0    0    0   \n",
       "\n",
       "   194  195  196  197  198  199  \n",
       "0    0    0    0    0    0    5  \n",
       "1    0    0    0    0    0    0  \n",
       "2    1    0   16    6    0    0  \n",
       "3    1    0    0    0   13    0  \n",
       "4    0    0    0    0    0    0  \n",
       "5    0    0    0    0    0    0  \n",
       "6    0    0    0    0    0    0  \n",
       "7    0    0    0    0    0    0  \n",
       "8    0    0    0    0    0    0  \n",
       "9    0    2    0    0    0    0  \n",
       "\n",
       "[10 rows x 200 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#便于观察 转化成df目测一下特征分布 共计200个词向量特征\n",
    "vec_df = pd.DataFrame(vec.fit_transform(x).toarray())\n",
    "vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 5]\n",
      " [2 0 2 ... 0 0 0]\n",
      " [0 2 0 ... 6 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "('体育', '体育', '体育', '体育', '体育', '娱乐', '娱乐', '娱乐', '娱乐', '娱乐')\n",
      "0.0748817616223546\n"
     ]
    }
   ],
   "source": [
    "'''计算单个特征与结果的互信息'''\n",
    "xx = vec.fit_transform(x).toarray()\n",
    "print(xx)\n",
    "print(y)\n",
    "\n",
    "print(mr.mutual_info_score(xx[:,0], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03873016 0.         0.         0.36039683 0.         0.06015873\n",
      " 0.         0.22218254 0.14944444 0.00123016 0.08277778 0.\n",
      " 1.20301587 0.02777778 0.0218254  0.         0.         0.\n",
      " 0.         0.20611111 0.13944444 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.08253968 0.18349206\n",
      " 0.12277778 0.         0.         0.         0.         0.\n",
      " 0.07801587 0.         0.         0.         0.01968254 0.08801587\n",
      " 0.04444444 0.         0.         0.         0.00944444 0.\n",
      " 0.         0.76230159 0.         0.24468254 0.08444444 0.18539683\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.14039683 0.06206349 0.         0.02706349 0.\n",
      " 0.03634921 0.         0.         0.         0.12539683 0.\n",
      " 0.04087302 0.13015873 0.05777778 0.13253968 0.16587302 0.08373016\n",
      " 0.21444444 0.         0.         0.         0.         0.02444444\n",
      " 0.         0.03253968 0.08444444 0.         0.         0.18539683\n",
      " 0.         0.         0.13944444 0.         0.13444444 0.\n",
      " 0.         0.00599206 0.         0.         0.         0.\n",
      " 0.14206349 0.12218254 0.06968254 0.33539683 0.07563492 0.\n",
      " 0.32611111 0.         0.08944444 0.         0.         0.\n",
      " 0.32611111 0.         0.01730159 0.         0.02003968 0.48896825\n",
      " 0.         0.03277778 0.         0.41777778 0.         0.\n",
      " 0.58396825 0.22611111 0.42706349 0.13611111 0.36539683 0.\n",
      " 0.         0.         0.15099206 0.         0.02896825 0.\n",
      " 0.         0.02896825 0.00777778 0.         0.         0.0718254\n",
      " 0.         0.         0.07301587 0.08849206 0.         0.\n",
      " 0.         0.07896825 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.33206349 0.01396825\n",
      " 0.         0.         0.         0.         0.         0.10277778\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.04039683 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.10277778 0.16587302 0.         0.         0.         0.\n",
      " 0.05873016 0.        ]\n"
     ]
    }
   ],
   "source": [
    "mutual_info = mutual_info_classif(xx,y,discrete_features=False,random_state=1)\n",
    "print(mutual_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2030158730158729\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(mutual_info.max())\n",
    "print(list(mutual_info).index(mutual_info.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7623015873015871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'奥斯卡'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(mutual_info)[55])\n",
    "list(vec.vocabulary_.keys())[list(vec.vocabulary_.values()).index(55)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2030158730158729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'体育讯'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(mutual_info)[12])\n",
    "list(vec.vocabulary_.keys())[list(vec.vocabulary_.values()).index(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'一位'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(mutual_info)[2])\n",
    "list(vec.vocabulary_.keys())[list(vec.vocabulary_.values()).index(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#该方法更适用于特征选取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他参考文章\n",
    "[关于互信息的一些注记](https://www.douban.com/note/621588501/)\n",
    "> 该文详细说明了，互信息（Mutual Information）如何作为特征选择指标，及互信息在此用途中的隐蔽缺陷，以及使用 normalized mutual information作为更合理指标的必要性。\n",
    "\n",
    "[特征选择](https://www.cnblogs.com/stevenlk/p/6543628.html)\n",
    "> 该文提到了最大信息系数方法，克服了互信息无法归一化以及对离散方式敏感的问题。它首先寻找一种最优的离散化方式，然后把互信息取值转换成一种度量方式，取值区间在[0，1]。 minepy 提供了MIC功能。\n",
    "\n",
    "[如何进行特征选择（理论篇）机器学习你会遇到的“坑”](https://baijiahao.baidu.com/s?id=1604074325918456186&wfr=spider&for=pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15774885315354795\n"
     ]
    }
   ],
   "source": [
    "'''标准化互信息NMI'''\n",
    "print(mr.normalized_mutual_info_score(xx[:,0], y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
