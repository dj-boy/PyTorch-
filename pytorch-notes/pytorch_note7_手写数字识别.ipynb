{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手写数字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import style\n",
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理\n",
    "_tran = transforms.Compose([\n",
    "    transforms.ToTensor(),  #将原始数据转换为张量\n",
    "    #torchvision.transforms.ToTensor：把一个取值范围是[0,255]的PIL.Image或者shape为(H,W,C)的numpy.ndarray，转换成形状为[C,H,W]，取值范围是[0,1.0]的torch.FloadTensor\n",
    "    #transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])  \n",
    "    #给定均值：(R,G,B) 方差：（R，G，B），将会把Tensor正则化。即：Normalized_image=(image-mean)/std \n",
    "    #ransforms.Normalize(mean,std)\n",
    "    #ToTensor 已经把数值归一化为0-1之间，故均值为0.5\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "#加载数据集\n",
    "mnist = MNIST(\"data\",download=True, train=True, transform=_tran)\n",
    "                                                     #train=False可加载测试集，但此处使用训练集，方便下面练习切分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "#DataLoader为多个处理器之间并行地批处理、加载和搬移数据提供了可能\n",
    "from torch.utils.data.sampler import SubsetRandomSampler #样本元素从指定的索引列表中随机抽取，没有替换\n",
    "\n",
    "#把训练集按2:8切分为训练集和测试集\n",
    "split = int(0.8*len(mnist))\n",
    "index_list = list(range(len(mnist)))\n",
    "train_idx,test_idx = index_list[:split], index_list[split:]\n",
    "\n",
    "trainloader = DataLoader(mnist,batch_size=256,sampler=SubsetRandomSampler(train_idx))\n",
    "testloader = DataLoader(mnist,batch_size=256,sampler=SubsetRandomSampler(test_idx))\n",
    "#batch_size:每个批次加载多少个样本\n",
    "#sampler: 定义从数据集中提取样本的策略     #此处为从指定的索引列表中随机抽取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算卷积后图片大小公式：\n",
    "\n",
    "假设：输入图片（Input）大小为I*I，卷积核（Filter）大小为K*K，步长（stride）为S，填充（Padding）的像素数为P，那卷积层输出（Output）的特征图大小为多少呢?\n",
    "    \n",
    "    可以得出推导公式：\n",
    "    O=（I-K+2P）/S+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(1,16,5,1,padding=2) \n",
    "#         #if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "#         self.conv2 = nn.Conv2d(16,32,5,1,padding=2)\n",
    "#         self.pool = nn.MaxPool2d(2,2)\n",
    "#         self.hidden = nn.Linear(32*7*7, 128) #每张图大小为28*28个节点\n",
    "#         self.output = nn.Linear(128, 10)\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))  #input_size: 1*28*28 --16*28*28 --池化后 16*14*14\n",
    "#         x = self.pool(F.relu(self.conv2(x))) #input_size: 16*14*14 --32*14*14 --池化后 32*7*7\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = F.relu(self.hidden(x))\n",
    "#         x = F.softmax(self.output(x),dim=1) #dim=1 跨列求softmax\n",
    "#         return x\n",
    "    \n",
    "# model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,4,kernel_size = 3,stride = 1,padding=1) \n",
    "        #if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "        self.conv2 = nn.Conv2d(4,16,3,1,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.hidden = nn.Linear(16*7*7, 128) #每张图大小为28*28个节点\n",
    "        self.output = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  #input_size: 1*28*28 --卷积后4*28*28 --池化后 4*14*14\n",
    "        x = self.pool(F.relu(self.conv2(x))) #input_size: 4*14*14 --卷积后16*14*14 --池化后 16*7*7\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = F.softmax(self.output(x),dim=1) #dim=1 跨列求softmax\n",
    "        return x\n",
    "    \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数和优化器\n",
    "from torch import optim\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss() #交叉熵损失函数\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=10e-08, weight_decay = 0)\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train loss: 2.2986151018041245 test loss: 2.298310244337041\n",
      "epoch: 2 train loss: 2.2977752710910555 test loss: 2.297414571680921\n",
      "epoch: 3 train loss: 2.296729468284769 test loss: 2.296277436804264\n",
      "epoch: 4 train loss: 2.2953211855381093 test loss: 2.294657240522669\n",
      "epoch: 5 train loss: 2.293349546320895 test loss: 2.2925257581345577\n",
      "epoch: 6 train loss: 2.2905187543402326 test loss: 2.289216954657372\n",
      "epoch: 7 train loss: 2.2857477614220154 test loss: 2.2832575199451854\n",
      "epoch: 8 train loss: 2.2764558297522526 test loss: 2.270760277484326\n",
      "epoch: 9 train loss: 2.25634398866207 test loss: 2.242911541715581\n",
      "epoch: 10 train loss: 2.2212641251848098 test loss: 2.204142631368434\n"
     ]
    }
   ],
   "source": [
    "# 开始训练模型\n",
    "for epoch in range(1,11):\n",
    "    train_loss, test_loss = [], []\n",
    "    #训练数据\n",
    "    model.train()\n",
    "    for data,y in trainloader: #按批次训练\n",
    "        optimizer.zero_grad()\n",
    "        #向前传播训练\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        #向后传播求导(梯度) 更新参数\n",
    "        loss.backward()\n",
    "        optimizer.step() #使用优化器更新权重\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    #模型评价\n",
    "    model.eval()\n",
    "    for data,y in testloader:\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        test_loss.append(loss.item())\n",
    "    print(\"epoch:\",epoch,\"train loss:\",np.mean(train_loss),\"test loss:\",np.mean(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train loss: 1.7364512631233702 test loss: 1.6182670263533896\n",
      "epoch: 2 train loss: 1.6080430860215045 test loss: 1.5972337316959462\n",
      "epoch: 3 train loss: 1.5914739192800318 test loss: 1.5842402209626867\n",
      "epoch: 4 train loss: 1.5835887650226026 test loss: 1.5810561890297747\n",
      "epoch: 5 train loss: 1.5502835309251826 test loss: 1.4993247250293165\n",
      "epoch: 6 train loss: 1.4926167276311428 test loss: 1.4906337235836273\n",
      "epoch: 7 train loss: 1.4889806160267363 test loss: 1.486969734760041\n",
      "epoch: 8 train loss: 1.485047847032547 test loss: 1.4866218795167638\n",
      "epoch: 9 train loss: 1.4824679506585954 test loss: 1.4862050426767228\n",
      "epoch: 10 train loss: 1.4818730094331376 test loss: 1.4829870614599674\n"
     ]
    }
   ],
   "source": [
    "#定义损失函数和优化器\n",
    "from torch import optim\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss() #交叉熵损失函数\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=10e-08, weight_decay = 0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# 开始训练模型\n",
    "for epoch in range(1,11):\n",
    "    train_loss, test_loss = [], []\n",
    "    #训练数据\n",
    "    model.train()\n",
    "    for data,y in trainloader: #按批次训练\n",
    "        optimizer.zero_grad()\n",
    "        #向前传播训练\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        #向后传播求导(梯度) 更新参数\n",
    "        loss.backward()\n",
    "        optimizer.step() #使用优化器更新权重\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    #模型评价\n",
    "    model.eval()\n",
    "    for data,y in testloader:\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        test_loss.append(loss.item())\n",
    "    print(\"epoch:\",epoch,\"train loss:\",np.mean(train_loss),\"test loss:\",np.mean(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 以上两种优化器结果对比可见：自适应性优化器Adam效果优于SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "#在验证集上进行预测\n",
    "dataiter = iter(testloader)  #iter迭代器\n",
    "\n",
    "data,test_y = dataiter.next()\n",
    "print(data.shape)\n",
    "print(type(data))\n",
    "\n",
    "#256个数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#举例\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[1].numpy().squeeze(),cmap='Greys_r')\n",
    "print(test_y[1])\n",
    "print(preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual: tensor([7, 9, 6, 2, 2, 2, 4, 5, 4, 0])\n",
      "predicted: [7 9 6 2 2 2 4 5 4 0]\n"
     ]
    }
   ],
   "source": [
    "#在验证集上进行预测\n",
    "\n",
    "output = model(data)\n",
    "_,y_pred = t.max(output,1) \n",
    "#t.max(a,0):返回每一列的最大值 以及对应的索引； t.max(a,1):返回每一行的最大值 以及对应的索引\n",
    "\n",
    "preds = np.squeeze(y_pred.numpy())\n",
    "print(\"actual:\", test_y[:10])\n",
    "print(\"predicted:\",preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000 张测试图片准确率为：98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "total = 0\n",
    "\n",
    "for data,y in testloader:\n",
    "    output = model(data)\n",
    "    _, preds = t.max(output,1)\n",
    "    total += y.size(0)\n",
    "    correct += (preds == y).sum()\n",
    "        \n",
    "print(\"%d 张测试图片准确率为：%d %%\" %(total,(100*correct/total)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
