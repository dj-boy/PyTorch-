{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用pytorch实现逻辑回归分类\n",
    "\n",
    "逻辑步骤比较简单，不再详述，只做简单总结：\n",
    "    \n",
    "    1.线性回归\n",
    "    2.sigmoid激活函数转化为0-1之间的概率值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手写数字\n",
    "\n",
    "代码总体和task2类似 只是改为逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理\n",
    "from torchvision import transforms\n",
    "\n",
    "_tran = transforms.Compose([\n",
    "    transforms.ToTensor(),  #将原始数据转换为张量\n",
    "    #torchvision.transforms.ToTensor：把一个取值范围是[0,255]的PIL.Image或者shape为(H,W,C)的numpy.ndarray，转换成形状为[C,H,W]，取值范围是[0,1.0]的torch.FloadTensor\n",
    "    #transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])  \n",
    "    #给定均值：(R,G,B) 方差：（R，G，B），将会把Tensor正则化。即：Normalized_image=(image-mean)/std \n",
    "    #ransforms.Normalize(mean,std)\n",
    "    #ToTensor 已经把数值归一化为0-1之间，故均值为0.5\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "#加载数据集\n",
    "mnist = MNIST(\"data\",download=True, train=True, transform=_tran)\n",
    "                                                     #train=False可加载测试集，但此处使用训练集，方便下面练习切分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "#DataLoader为多个处理器之间并行地批处理、加载和搬移数据提供了可能\n",
    "from torch.utils.data.sampler import SubsetRandomSampler #样本元素从指定的索引列表中随机抽取，没有替换\n",
    "\n",
    "#把训练集按2:8切分为训练集和测试集\n",
    "split = int(0.8*len(mnist))\n",
    "index_list = list(range(len(mnist)))\n",
    "train_idx,test_idx = index_list[:split], index_list[split:]\n",
    "\n",
    "trainloader = DataLoader(mnist,batch_size=256,sampler=SubsetRandomSampler(train_idx))\n",
    "testloader = DataLoader(mnist,batch_size=256,sampler=SubsetRandomSampler(test_idx))\n",
    "#batch_size:每个批次加载多少个样本\n",
    "#sampler: 定义从数据集中提取样本的策略     #此处为从指定的索引列表中随机抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(784, 10) #每张图大小为28*28个节点\n",
    "        self.output = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0],784)\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数和优化器\n",
    "from torch import optim\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss() #交叉熵损失函数\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay = 1e-5, momentum=0.9, nesterov=True)\n",
    "#lr:学习率 weight_decay:权重衰减，L2惩罚    momentum:冲量，动量因子，相当于考虑惯性的力量     nesterov:是否使用动量\n",
    "\n",
    "#SGD 把数据分批放入nn进行训练，节省资源、加速了计算过程，且损失了较少的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train loss: 0.34810554030093743 test loss: 0.31304482196239714\n",
      "epoch: 2 train loss: 0.3250737820375473 test loss: 0.2992754984409251\n",
      "epoch: 3 train loss: 0.31210468955179477 test loss: 0.2922257514710122\n",
      "epoch: 4 train loss: 0.3043485184774754 test loss: 0.2874277240418373\n",
      "epoch: 5 train loss: 0.29795038192830187 test loss: 0.2878999706912548\n",
      "epoch: 6 train loss: 0.2937854992899489 test loss: 0.2845946341118914\n",
      "epoch: 7 train loss: 0.29035001422496554 test loss: 0.28872496238414275\n",
      "epoch: 8 train loss: 0.2872965484857559 test loss: 0.27838166501927886\n",
      "epoch: 9 train loss: 0.28446969802075245 test loss: 0.2793362923759095\n",
      "epoch: 10 train loss: 0.281816654858437 test loss: 0.2791473386769599\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 开始训练模型\n",
    "for epoch in range(1,11):\n",
    "    train_loss, test_loss = [], []\n",
    "    #训练数据\n",
    "    model.train()\n",
    "    for data,y in trainloader: #按批次训练\n",
    "        optimizer.zero_grad()\n",
    "        #向前传播训练\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        #向后传播求导(梯度) 更新参数\n",
    "        loss.backward()\n",
    "        optimizer.step() #使用优化器更新权重\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    #模型评价\n",
    "    model.eval()\n",
    "    for data,y in testloader:\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        test_loss.append(loss.item())\n",
    "    print(\"epoch:\",epoch,\"train loss:\",np.mean(train_loss),\"test loss:\",np.mean(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "\n",
    "#在验证集上进行预测\n",
    "dataiter = iter(testloader)  #iter迭代器\n",
    "\n",
    "data,test_y = dataiter.next()\n",
    "print(data.shape)\n",
    "print(type(data))\n",
    "\n",
    "#256个数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual: tensor([8, 1, 0, 3, 0, 6, 4, 7, 6, 2])\n",
      "predicted: [8 1 0 9 0 6 4 7 6 2]\n"
     ]
    }
   ],
   "source": [
    "#在验证集上进行预测\n",
    "\n",
    "output = model(data)\n",
    "_,y_pred = t.max(output,1) \n",
    "#t.max(a,0):返回每一列的最大值 以及对应的索引； t.max(a,1):返回每一行的最大值 以及对应的索引\n",
    "\n",
    "preds = np.squeeze(y_pred.numpy())\n",
    "print(\"actual:\", test_y[:10])\n",
    "print(\"predicted:\",preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#举例\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[3].numpy().squeeze(),cmap='Greys_r')\n",
    "print(test_y[3])\n",
    "print(preds[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.array(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n",
      "256\n",
      "accuracy of model is 236 / 256 : 92.19%\n"
     ]
    }
   ],
   "source": [
    "#准确率\n",
    "correct = 0\n",
    "t_y = np.array(test_y)\n",
    "\n",
    "for i in range(len(t_y)):\n",
    "    if test_y[i]==preds[i]:\n",
    "        correct +=1\n",
    "\n",
    "print(correct)\n",
    "print(len(t_y))\n",
    "print(\"accuracy of model is %d / %d : %.2f%%\" %(correct, len(t_y), 100*correct/len(t_y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
