{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 物体图像分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torch as t\n",
    "import torchvision.transforms as transforms \n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#对数据预处理\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(), #转为tensor\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "#下载数据\n",
    "#训练数据\n",
    "trainset = tv.datasets.CIFAR10('./',train=True,download=True,transform = trans)\n",
    "trainloader = t.utils.data.DataLoader(trainset, \n",
    "                                                    batch_size = 4,\n",
    "                                                    shuffle = True,\n",
    "                                                    num_workers =2) \n",
    "#测试数据\n",
    "testset = tv.datasets.CIFAR10('./',train=False,download=True,transform = trans)\n",
    "testloader = t.utils.data.DataLoader(testset, \n",
    "                                                    batch_size = 4,\n",
    "                                                    shuffle = True,\n",
    "                                                    num_workers =2) \n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,3,padding=1) #输入通道数，输出通道数，卷积层\n",
    "        self.conv2 = nn.Conv2d(16,32,3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)  #池化层\n",
    "        self.linear1 = nn.Linear(1024,512)   #64*2*2\n",
    "        self.linear2 = nn.Linear(512,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  #卷积-激活函数-池化\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1,1024)  #reshape\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数和优化器\n",
    "import torch.optim as optim\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, weight_decay = 1e-6, momentum = 0.9,  nesterov= True)  \n",
    "#lr: 学习率\n",
    "#weight_decay：基本思想就是减小不重要的参数对最后结果的影响，网络中有用的权重则不会收到Weight decay影响\n",
    "#nesterov: 确定是否使用Nesterov动量\n",
    "#moment: 动量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 2.857\n",
      "[1, 4000] loss: 2.700\n",
      "[1, 6000] loss: 1.423\n",
      "[1, 8000] loss: 2.554\n",
      "[1,10000] loss: 2.353\n",
      "[1,12000] loss: 0.989\n",
      "[2, 2000] loss: 1.753\n",
      "[2, 4000] loss: 1.861\n",
      "[2, 6000] loss: 2.276\n",
      "[2, 8000] loss: 2.204\n",
      "[2,10000] loss: 1.863\n",
      "[2,12000] loss: 1.395\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    train_loss, test_loss = [], []\n",
    "    #训练\n",
    "    model.train()\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        data,y = data\n",
    "        optimizer.zero_grad()  #梯度清零\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        loss.backward()\n",
    "        #更新参数\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        if i%2000 == 1999:\n",
    "            print('[%d,%5d] loss: %.3f' %(epoch+1,i+1,train_loss[i]))\n",
    "    #评价\n",
    "    model.eval()\n",
    "    for data,y in testloader:\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        test_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4000] loss: 1.890\n",
      "[1, 8000] loss: 1.281\n",
      "[1,12000] loss: 1.667\n",
      "[2, 4000] loss: 0.962\n",
      "[2, 8000] loss: 1.547\n",
      "[2,12000] loss: 1.593\n",
      "[3, 4000] loss: 1.077\n",
      "[3, 8000] loss: 0.545\n",
      "[3,12000] loss: 1.436\n",
      "[4, 4000] loss: 1.296\n",
      "[4, 8000] loss: 1.213\n",
      "[4,12000] loss: 1.815\n",
      "[5, 4000] loss: 0.885\n",
      "[5, 8000] loss: 1.951\n",
      "[5,12000] loss: 0.807\n",
      "[6, 4000] loss: 0.664\n",
      "[6, 8000] loss: 1.162\n",
      "[6,12000] loss: 0.595\n",
      "[7, 4000] loss: 0.487\n",
      "[7, 8000] loss: 0.071\n",
      "[7,12000] loss: 1.137\n",
      "[8, 4000] loss: 0.222\n",
      "[8, 8000] loss: 0.920\n",
      "[8,12000] loss: 0.780\n",
      "[9, 4000] loss: 0.871\n",
      "[9, 8000] loss: 0.340\n",
      "[9,12000] loss: 0.207\n",
      "[10, 4000] loss: 0.006\n",
      "[10, 8000] loss: 0.508\n",
      "[10,12000] loss: 1.469\n",
      "[11, 4000] loss: 0.101\n",
      "[11, 8000] loss: 0.054\n",
      "[11,12000] loss: 1.119\n"
     ]
    }
   ],
   "source": [
    "#可以看到损失函数波动起伏不定。\n",
    "#下面减小学习率&增加迭代次数重新训练\n",
    "\n",
    "#由于mac系统不支持gpu，避免训练时间过长 当前迭代次数设置的较小 \n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, weight_decay = 1e-6, momentum = 0.9,  nesterov= True)  \n",
    "\n",
    "t.set_num_threads(8)\n",
    "for epoch in range(11):\n",
    "    train_loss, test_loss = [], []\n",
    "    #训练\n",
    "    model.train()\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        data,y = data\n",
    "        optimizer.zero_grad()  #梯度清零\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        loss.backward()\n",
    "        #更新参数\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        if i%4000 == 3999:\n",
    "            print('[%d,%5d] loss: %.3f' %(epoch+1,i+1,train_loss[i]))\n",
    "    #评价\n",
    "    model.eval()\n",
    "    for data,y in testloader:\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        test_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集表现\n",
    "dataiter = iter(testloader) \n",
    "data,labels = dataiter.next()  #每个批次4个样本\n",
    "output = model(data)\n",
    "_,preds = t.max(output,1)  #axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 9, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.squeeze(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual: ['cat', 'bird', 'deer', 'car']\n",
      "preds: ['cat', 'bird', 'horse', 'car']\n"
     ]
    }
   ],
   "source": [
    "print(\"actual:\", [classes[labels[i]] for i in range(4)])\n",
    "print(\"preds:\" ,[classes[preds[i]] for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 张测试图片准确率为：56 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "total = 0\n",
    "\n",
    "for data,y in testloader:\n",
    "    output = model(data)\n",
    "    _, preds = t.max(output,1)\n",
    "    total += y.size(0)\n",
    "    correct += (preds == y).sum()\n",
    "        \n",
    "print(\"%d 张测试图片准确率为：%d %%\" %(total,(100*correct/total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
