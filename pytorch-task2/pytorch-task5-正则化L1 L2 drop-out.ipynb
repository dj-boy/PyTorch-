{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 物体图像分类\n",
    "大部分代码均沿用task4 此任务主要改变dropout进行对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下用自己的理解陈述一下过拟合的一般解决方案：\n",
    "\n",
    "    1）增加数据集\n",
    "    2）降低训练复杂度\n",
    "    \n",
    "降低复杂度常用的使用方法：\n",
    "    \n",
    "    1）正则化\n",
    "    2）dropout\n",
    "    3）其他降低模型复杂度的参数（如机器学习中树的深度等）\n",
    "\n",
    "此处为深度学习，主要讨论前两种\n",
    "\n",
    "1. 正则化：L1正则化，即在原有的损失函数的基础上添加参数向量的L1范数。可以简单理解为对系数绝对值之和加入惩罚项以达到减少过拟合的情况。L1正则化可以使系数降为0。\n",
    "               L2正则化，即在原有的损失函数的基础上添加参数向量的L2范数。可以简单理解为系数平方和加入惩罚项以达到减少过拟合的情况。L2正则化使系数趋近为0。\n",
    "               \n",
    "               pytorch自带的损失函数只有L2正则化参数（weight_decay）,L1正则化则需要手动实现。\n",
    "               \n",
    "               \n",
    "               \n",
    "2. dropout：dropout主要是让神经元的激活值以一定的概率停止工作，从而降低复杂度是模型泛化性更强。\n",
    "\n",
    "注：为了加快运算速度，下面的训练调参较为简单，主要为了方便对比正则化结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torch as t\n",
    "import torchvision.transforms as transforms \n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#对数据预处理\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(), #转为tensor\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "#下载数据\n",
    "#训练数据\n",
    "trainset = tv.datasets.CIFAR10('./',train=True,download=True,transform = trans)\n",
    "trainloader = t.utils.data.DataLoader(trainset, \n",
    "                                                    batch_size = 4,\n",
    "                                                    shuffle = True,\n",
    "                                                    num_workers =2) \n",
    "#测试数据\n",
    "testset = tv.datasets.CIFAR10('./',train=False,download=True,transform = trans)\n",
    "testloader = t.utils.data.DataLoader(testset, \n",
    "                                                    batch_size = 4,\n",
    "                                                    shuffle = True,\n",
    "                                                    num_workers =2) \n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,3,padding=1) #输入通道数，输出通道数，卷积层\n",
    "        self.conv2 = nn.Conv2d(16,32,3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)  #池化层\n",
    "        self.linear1 = nn.Linear(1024,512)   #64*2*2\n",
    "        self.linear2 = nn.Linear(512,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  #卷积-激活函数-池化\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1,1024)  #reshape\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数和优化器\n",
    "import torch.optim as optim\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, weight_decay = 0, momentum = 0.9,  nesterov= True)  \n",
    "#lr: 学习率\n",
    "#weight_decay：基本思想就是减小不重要的参数对最后结果的影响，网络中有用的权重则不会收到Weight decay影响\n",
    "#nesterov: 确定是否使用Nesterov动量\n",
    "#moment: 动量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 1.632\n",
      "[1, 4000] loss: 1.727\n",
      "[1, 6000] loss: 1.465\n",
      "[1, 8000] loss: 2.716\n",
      "[1,10000] loss: 2.293\n",
      "[1,12000] loss: 1.965\n",
      "[2, 2000] loss: 1.475\n",
      "[2, 4000] loss: 1.842\n",
      "[2, 6000] loss: 1.732\n",
      "[2, 8000] loss: 2.270\n",
      "[2,10000] loss: 1.997\n",
      "[2,12000] loss: 2.626\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    train_loss, test_loss = [], []\n",
    "    #训练\n",
    "    model.train()\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        data,y = data\n",
    "        optimizer.zero_grad()  #梯度清零\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        loss.backward()\n",
    "        #更新参数\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        if i%2000 == 1999:\n",
    "            print('[%d,%5d] loss: %.3f' %(epoch+1,i+1,train_loss[i]))\n",
    "    #评价\n",
    "    model.eval()\n",
    "    for data,y in testloader:\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        test_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集表现\n",
    "dataiter = iter(testloader) \n",
    "data,labels = dataiter.next()  #每个批次4个样本\n",
    "output = model(data)\n",
    "_,preds = t.max(output,1)  #axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 9, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.squeeze(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual: ['dog', 'cat', 'plane', 'car']\n",
      "preds: ['deer', 'frog', 'car', 'car']\n"
     ]
    }
   ],
   "source": [
    "print(\"actual:\", [classes[labels[i]] for i in range(4)])\n",
    "print(\"preds:\" ,[classes[preds[i]] for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 张测试图片准确率为：36 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "total = 0\n",
    "\n",
    "for data,y in testloader:\n",
    "    output = model(data)\n",
    "    _, preds = t.max(output,1)\n",
    "    total += y.size(0)\n",
    "    correct += (preds == y).sum()\n",
    "        \n",
    "print(\"%d 张测试图片准确率为：%d %%\" %(total,(100*correct/total)))\n",
    "\n",
    "\n",
    "## 为了节省计算资源 只迭代了2次 以致准确率较低，实际项目中要增加迭代次数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,3,padding=1) #输入通道数，输出通道数，卷积层\n",
    "        self.conv2 = nn.Conv2d(16,32,3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)  #池化层\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear1 = nn.Linear(1024,512)   #64*2*2\n",
    "        self.linear2 = nn.Linear(512,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  #卷积-激活函数-池化\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1,1024)  #reshape\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout (x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#正则化dropout=0.5 L2=0\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, weight_decay = 0, momentum = 0.9,  nesterov= True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 2.449\n",
      "[1, 4000] loss: 2.107\n",
      "[1, 6000] loss: 2.345\n",
      "[1, 8000] loss: 2.103\n",
      "[1,10000] loss: 2.082\n",
      "[1,12000] loss: 2.715\n",
      "[2, 2000] loss: 1.451\n",
      "[2, 4000] loss: 1.612\n",
      "[2, 6000] loss: 2.237\n",
      "[2, 8000] loss: 1.857\n",
      "[2,10000] loss: 2.252\n",
      "[2,12000] loss: 2.346\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    train_loss, test_loss = [], []\n",
    "    #训练\n",
    "    model.train()\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        data,y = data\n",
    "        optimizer.zero_grad()  #梯度清零\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        loss.backward()\n",
    "        #更新参数\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        if i%2000 == 1999:\n",
    "            print('[%d,%5d] loss: %.3f' %(epoch+1,i+1,train_loss[i]))\n",
    "    #评价\n",
    "    model.eval()\n",
    "    for data,y in testloader:\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        test_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,3,padding=1) #输入通道数，输出通道数，卷积层\n",
    "        self.conv2 = nn.Conv2d(16,32,3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)  #池化层\n",
    "        self.linear1 = nn.Linear(1024,512)   #64*2*2\n",
    "        self.linear2 = nn.Linear(512,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  #卷积-激活函数-池化\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1,1024)  #reshape\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 2.309\n",
      "[1, 4000] loss: 2.296\n",
      "[1, 6000] loss: 2.288\n",
      "[1, 8000] loss: 2.303\n",
      "[1,10000] loss: 2.315\n",
      "[1,12000] loss: 2.286\n",
      "[2, 2000] loss: 2.296\n",
      "[2, 4000] loss: 2.312\n",
      "[2, 6000] loss: 2.314\n",
      "[2, 8000] loss: 2.319\n",
      "[2,10000] loss: 2.300\n",
      "[2,12000] loss: 2.298\n"
     ]
    }
   ],
   "source": [
    "#正则化L2=0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, weight_decay = 1, momentum = 0.9,  nesterov= True)  \n",
    "\n",
    "for epoch in range(2):\n",
    "    train_loss, test_loss = [], []\n",
    "    #训练\n",
    "    model.train()\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        data,y = data\n",
    "        optimizer.zero_grad()  #梯度清零\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        loss.backward()\n",
    "        #更新参数\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        if i%2000 == 1999:\n",
    "            print('[%d,%5d] loss: %.3f' %(epoch+1,i+1,train_loss[i]))\n",
    "    #评价\n",
    "    model.eval()\n",
    "    for data,y in testloader:\n",
    "        output = model(data)\n",
    "        loss = loss_func(output,y)\n",
    "        test_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集表现\n",
    "dataiter = iter(testloader) \n",
    "data,labels = dataiter.next()  #每个批次4个样本\n",
    "output = model(data)\n",
    "_,preds = t.max(output,1)  #axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual: ['plane', 'horse', 'car', 'bird']\n",
      "preds: ['truck', 'truck', 'truck', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print(\"actual:\", [classes[labels[i]] for i in range(4)])\n",
    "print(\"preds:\" ,[classes[preds[i]] for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 张测试图片准确率为：10 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "total = 0\n",
    "\n",
    "for data,y in testloader:\n",
    "    output = model(data)\n",
    "    _, preds = t.max(output,1)\n",
    "    total += y.size(0)\n",
    "    correct += (preds == y).sum()\n",
    "        \n",
    "print(\"%d 张测试图片准确率为：%d %%\" %(total,(100*correct/total)))\n",
    "\n",
    "##为了对比正则化的效果，正则化系数调整较大，可以看到在迭代次数过少的情况下严重欠拟合\n",
    "#但在训练较为复杂时，适度正则化可以增加模型的鲁棒性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，加入正则化之后，在模型训练次数较少时（上面例子迭代次数较少，为了节省计算时间，未增加迭代次数进行深入训练），模型更容易欠拟合；\n",
    "\n",
    "另一方面，加入正则化之后，明显看到损失函数变化趋势波动减小，下降趋势变慢，更加平滑。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
